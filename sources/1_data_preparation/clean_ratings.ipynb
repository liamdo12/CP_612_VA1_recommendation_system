{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Handle missing data for ratings",
   "id": "ef3c29094c7b8081"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:33:57.111979Z",
     "start_time": "2025-10-25T03:33:53.701137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../datasets/input/ratings.csv', low_memory=False)\n",
    "data = df.copy()"
   ],
   "id": "cf19a6de2058ac6a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rating analysis",
   "id": "6cd2dbc0e7efa885"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:34:17.794476Z",
     "start_time": "2025-10-25T03:34:17.756254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Columns with missing data: \\n\")\n",
    "missing_data = []\n",
    "\n",
    "for column in data.columns:\n",
    "    missing_count = data[column].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_pct = (missing_count / len(data)) * 100\n",
    "        missing_data.append({\n",
    "            'Column': column,\n",
    "            'Missing count': missing_count,\n",
    "            'Missing percentage': f\"{missing_pct:.2f}%\",\n",
    "        })\n",
    "        print(f\"{column:30} | {missing_count} missing {missing_pct:5.2f}%\")\n",
    "\n",
    "print(f\"Total columns: {len(data.columns)}\")\n",
    "print(f\"Total missing data: {len(missing_data)}\")\n",
    "print(f\"Columns without missing data: {len(data.columns) - len(missing_data)}\")"
   ],
   "id": "96134d180aad9ef2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data: \n",
      "\n",
      "Total columns: 4\n",
      "Total missing data: 0\n",
      "Columns without missing data: 4\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1: Check for duplicate ratings (same user-movie pair)",
   "id": "306731ab092e769"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:34:19.929972Z",
     "start_time": "2025-10-25T03:34:18.980594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for duplicate user-movie pairs\n",
    "duplicates = data.groupby(['userId', 'movieId']).size()\n",
    "duplicate_pairs = duplicates[duplicates > 1]\n",
    "\n",
    "print(f\"Total ratings: {len(data)}\")\n",
    "print(f\"Unique user-movie pairs: {len(duplicates)}\")\n",
    "print(f\"Duplicate user-movie pairs: {len(duplicate_pairs)}\")\n",
    "\n",
    "if len(duplicate_pairs) > 0:\n",
    "    duplicate_percentage = (len(duplicate_pairs) / len(duplicates)) * 100\n",
    "    print(f\"Percentage of duplicates: {duplicate_percentage:.2f}%\")\n",
    "    \n",
    "\n",
    "    print(\"\\nExamples of duplicate ratings:\")\n",
    "    sample_duplicate = duplicate_pairs.head(3)\n",
    "    for (userId, movieId), count in sample_duplicate.items():\n",
    "        print(f\"\\nUser {userId}, Movie {movieId} - rated {count} times:\")\n",
    "        print(data[(data['userId'] == userId) & (data['movieId'] == movieId)][['userId', 'movieId', 'rating', 'timestamp']])\n",
    "else:\n",
    "    print(\"\\nNo duplicate ratings found.\")"
   ],
   "id": "1cf8931f7dec4e22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ratings: 26024289\n",
      "Unique user-movie pairs: 26024289\n",
      "Duplicate user-movie pairs: 0\n",
      "\n",
      "No duplicate ratings found.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Save cleaned ratings dataset",
   "id": "72c528e0a4b21eeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:34:37.019477Z",
     "start_time": "2025-10-25T03:34:20.881859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save cleaned ratings to CSV (after all cleaning steps)\n",
    "output_path = '../../datasets/output/cleaned_datasets/cleaned_ratings.csv'\n",
    "data.to_csv(output_path, index=False)\n"
   ],
   "id": "82fd40b3cd87c60a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b5896fb1a0856c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
