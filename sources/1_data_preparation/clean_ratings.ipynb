{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Handle missing data for ratings",
   "id": "ef3c29094c7b8081"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../datasets/input/ratings.csv', low_memory=False)\n",
    "data = df.copy()"
   ],
   "id": "cf19a6de2058ac6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rating analysis",
   "id": "6cd2dbc0e7efa885"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Columns with missing data: \\n\")\n",
    "missing_data = []\n",
    "\n",
    "for column in data.columns:\n",
    "    missing_count = data[column].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_pct = (missing_count / len(data)) * 100\n",
    "        missing_data.append({\n",
    "            'Column': column,\n",
    "            'Missing count': missing_count,\n",
    "            'Missing percentage': f\"{missing_pct:.2f}%\",\n",
    "        })\n",
    "        print(f\"{column:30} | {missing_count} missing {missing_pct:5.2f}%\")\n",
    "\n",
    "print(f\"Total columns: {len(data.columns)}\")\n",
    "print(f\"Total missing data: {len(missing_data)}\")\n",
    "print(f\"Columns without missing data: {len(data.columns) - len(missing_data)}\")"
   ],
   "id": "96134d180aad9ef2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1: Check for duplicate ratings (same user-movie pair)",
   "id": "306731ab092e769"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check for duplicate user-movie pairs\n",
    "duplicates = data.groupby(['userId', 'movieId']).size()\n",
    "duplicate_pairs = duplicates[duplicates > 1]\n",
    "\n",
    "print(f\"Total ratings: {len(data)}\")\n",
    "print(f\"Unique user-movie pairs: {len(duplicates)}\")\n",
    "print(f\"Duplicate user-movie pairs: {len(duplicate_pairs)}\")\n",
    "\n",
    "if len(duplicate_pairs) > 0:\n",
    "    duplicate_percentage = (len(duplicate_pairs) / len(duplicates)) * 100\n",
    "    print(f\"Percentage of duplicates: {duplicate_percentage:.2f}%\")\n",
    "    \n",
    "\n",
    "    print(\"\\nExamples of duplicate ratings:\")\n",
    "    sample_duplicate = duplicate_pairs.head(3)\n",
    "    for (userId, movieId), count in sample_duplicate.items():\n",
    "        print(f\"\\nUser {userId}, Movie {movieId} - rated {count} times:\")\n",
    "        print(data[(data['userId'] == userId) & (data['movieId'] == movieId)][['userId', 'movieId', 'rating', 'timestamp']])\n",
    "else:\n",
    "    print(\"\\nNo duplicate ratings found.\")"
   ],
   "id": "1cf8931f7dec4e22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Save cleaned ratings dataset",
   "id": "72c528e0a4b21eeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save cleaned ratings to CSV (after all cleaning steps)\n",
    "output_path = '../../datasets/output/cleaned_datasets/cleaned_ratings.csv'\n",
    "data.to_csv(output_path, index=False)\n"
   ],
   "id": "82fd40b3cd87c60a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b5896fb1a0856c"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
