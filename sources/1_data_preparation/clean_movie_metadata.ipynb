{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Handle missing data for movie metadata",
   "id": "8685bf49cc1d2917"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-11T04:35:05.936885Z",
     "start_time": "2025-10-11T04:35:05.685952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../datasets/input/movies_metadata.csv',\n",
    "                 dtype={'id': str},\n",
    "                 low_memory=False)\n",
    "data = df.copy()"
   ],
   "id": "a240d25c41505bc9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Movies metadata analysis",
   "id": "ff69667b5a8a7a13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T04:35:07.462370Z",
     "start_time": "2025-10-11T04:35:07.443961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing data in each column\n",
    "print(\"Columns with missing data:\\n\")\n",
    "\n",
    "missing_data = []\n",
    "for column in data.columns:\n",
    "    missing_count = data[column].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_pct = (missing_count / len(data)) * 100\n",
    "        missing_data.append({\n",
    "            'Column': column,\n",
    "            'Missing Count': missing_count,\n",
    "            'Missing %': f\"{missing_pct:.2f}%\"\n",
    "        })\n",
    "        print(f\"{column:30} | {missing_count:6} missing ({missing_pct:5.2f}%)\")\n",
    "\n",
    "print(f\"Total columns: {len(data.columns)}\")\n",
    "print(f\"Columns with missing data: {len(missing_data)}\")\n",
    "print(f\"Columns without missing data: {len(data.columns) - len(missing_data)}\")"
   ],
   "id": "d568029dfbb6c38f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data:\n",
      "\n",
      "belongs_to_collection          |  40972 missing (90.12%)\n",
      "homepage                       |  37684 missing (82.88%)\n",
      "imdb_id                        |     17 missing ( 0.04%)\n",
      "original_language              |     11 missing ( 0.02%)\n",
      "overview                       |    954 missing ( 2.10%)\n",
      "popularity                     |      5 missing ( 0.01%)\n",
      "poster_path                    |    386 missing ( 0.85%)\n",
      "production_companies           |      3 missing ( 0.01%)\n",
      "production_countries           |      3 missing ( 0.01%)\n",
      "release_date                   |     87 missing ( 0.19%)\n",
      "revenue                        |      6 missing ( 0.01%)\n",
      "runtime                        |    263 missing ( 0.58%)\n",
      "spoken_languages               |      6 missing ( 0.01%)\n",
      "status                         |     87 missing ( 0.19%)\n",
      "tagline                        |  25054 missing (55.10%)\n",
      "title                          |      6 missing ( 0.01%)\n",
      "video                          |      6 missing ( 0.01%)\n",
      "vote_average                   |      6 missing ( 0.01%)\n",
      "vote_count                     |      6 missing ( 0.01%)\n",
      "Total columns: 24\n",
      "Columns with missing data: 19\n",
      "Columns without missing data: 5\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1: Fix malformed id field",
   "id": "42fe2b0eec373db7"
  },
  {
   "cell_type": "code",
   "id": "sq3ppn90w1q",
   "source": [
    "# Convert id to numeric, coercing errors to NaN\n",
    "print(f\"Original row count: {len(data)}\")\n",
    "\n",
    "data['id'] = pd.to_numeric(data['id'], errors='coerce')\n",
    "\n",
    "# Count how many rows have malformed id\n",
    "malformed_id_count = data['id'].isnull().sum()\n",
    "\n",
    "# Show examples of malformed rows (before dropping)\n",
    "if malformed_id_count > 0:\n",
    "    print(data[data['id'].isnull()][['id', 'title', 'original_title']].head())"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T04:35:08.895801Z",
     "start_time": "2025-10-11T04:35:08.880818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row count: 45466\n",
      "       id title                            original_title\n",
      "19730 NaN   NaN  [{'iso_639_1': 'en', 'name': 'English'}]\n",
      "29503 NaN   NaN      [{'iso_639_1': 'ja', 'name': '日本語'}]\n",
      "35587 NaN   NaN  [{'iso_639_1': 'en', 'name': 'English'}]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "5g3p1j9ieg5",
   "source": "# Step 2: Drop rows with missing critical fields (id, title)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "tyzyxloob8b",
   "source": "# Drop rows with missing id or title\nrows_before = len(data)\n\ndata = data.dropna(subset=['id', 'title'])\n\nrows_dropped = rows_before - len(data)\nprint(f\"Rows dropped due to missing id or title: {rows_dropped}\")\nprint(f\"Remaining rows: {len(data)}\")\n\n# Convert id to integer\ndata['id'] = data['id'].astype(int)\nprint(f\"\\nData types after cleaning:\")\nprint(data[['id', 'title']].dtypes)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T04:35:10.829513Z",
     "start_time": "2025-10-11T04:35:10.815197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped due to missing id or title: 6\n",
      "Remaining rows: 45460\n",
      "\n",
      "Data types after cleaning:\n",
      "id        int64\n",
      "title    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "bvk1uh2eodw",
   "source": "# Step 3: Parse JSON columns (genres, production_companies, etc.)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "akjrzt940ua",
   "source": [
    "import ast\n",
    "\n",
    "def parse_json_column(json_str):\n",
    "    try:\n",
    "        if pd.isna(json_str):\n",
    "            return []\n",
    "        data = ast.literal_eval(json_str)\n",
    "        if isinstance(data, list):\n",
    "            return [item['name'] for item in data if 'name' in item]\n",
    "        return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Parse genres\n",
    "data['genres_list'] = data['genres'].apply(parse_json_column)\n",
    "\n",
    "# Parse production_companies\n",
    "data['production_companies_list'] = data['production_companies'].apply(parse_json_column)\n",
    "\n",
    "# Parse production_countries\n",
    "data['production_countries_list'] = data['production_countries'].apply(parse_json_column)\n",
    "\n",
    "# Parse spoken_languages\n",
    "data['spoken_languages_list'] = data['spoken_languages'].apply(parse_json_column)\n",
    "\n",
    "print(data[['title', 'genres_list', 'production_companies_list']].head(3))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T04:35:14.889383Z",
     "start_time": "2025-10-11T04:35:13.180899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              title                   genres_list  \\\n",
      "0         Toy Story   [Animation, Comedy, Family]   \n",
      "1           Jumanji  [Adventure, Fantasy, Family]   \n",
      "2  Grumpier Old Men             [Romance, Comedy]   \n",
      "\n",
      "                           production_companies_list  \n",
      "0                          [Pixar Animation Studios]  \n",
      "1  [TriStar Pictures, Teitler Film, Interscope Co...  \n",
      "2                     [Warner Bros., Lancaster Gate]  \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "rk02i6475e",
   "source": "# Step 4: Save cleaned dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "gex061zmpg7",
   "source": [
    "\n",
    "columns_to_keep = [\n",
    "    'id', 'title', 'original_title', 'release_date', 'runtime',\n",
    "    'budget', 'revenue', 'popularity', 'vote_average', 'vote_count',\n",
    "    'overview', 'tagline', 'imdb_id', 'original_language', 'status',\n",
    "    'genres_list', 'production_companies_list', \n",
    "    'production_countries_list', 'spoken_languages_list'\n",
    "]\n",
    "\n",
    "cleaned_data = data[columns_to_keep].copy()\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../../datasets/output/cleaned_datasets/cleaned_movies_metadata.csv'\n",
    "cleaned_data.to_csv(output_path, index=False)\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T04:35:20.841550Z",
     "start_time": "2025-10-11T04:35:20.514779Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "baa444111026880c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
