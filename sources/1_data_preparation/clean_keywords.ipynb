{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "# Handle missing data for Keywords (Order 4 - Optional)"
   ]
  },
  {
   "cell_type": "code",
   "id": "load_dataset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:57:03.169542Z",
     "start_time": "2025-10-25T03:57:02.916773Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('../../datasets/input/keywords.csv')\n",
    "data = df.copy()\n",
    "\n",
    "print(f\"Dataset loaded: {len(data)} rows, {len(data.columns)} columns\")\n",
    "print(f\"Columns: {list(data.columns)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 46419 rows, 2 columns\n",
      "Columns: ['id', 'keywords']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "missing_data_analysis",
   "metadata": {},
   "source": [
    "# Keywords Missing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "check_missing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:57:04.075613Z",
     "start_time": "2025-10-25T03:57:04.069100Z"
    }
   },
   "source": [
    "print(\"Columns with missing data:\\n\")\n",
    "\n",
    "missing_data = []\n",
    "for column in data.columns:\n",
    "    missing_count = data[column].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_pct = (missing_count / len(data)) * 100\n",
    "        missing_data.append({\n",
    "            'Column': column,\n",
    "            'Missing Count': missing_count,\n",
    "            'Missing %': f\"{missing_pct:.2f}%\"\n",
    "        })\n",
    "        print(f\"{column:30} | {missing_count:6} missing ({missing_pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal columns: {len(data.columns)}\")\n",
    "print(f\"Columns with missing data: {len(missing_data)}\")\n",
    "print(f\"Columns without missing data: {len(data.columns) - len(missing_data)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data:\n",
      "\n",
      "\n",
      "Total columns: 2\n",
      "Columns with missing data: 0\n",
      "Columns without missing data: 2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "# Step 1: Drop rows with missing id"
   ]
  },
  {
   "cell_type": "code",
   "id": "drop_missing_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:57:05.578972Z",
     "start_time": "2025-10-25T03:57:05.573020Z"
    }
   },
   "source": [
    "# Drop rows with missing id (cannot merge without this field)\n",
    "rows_before = len(data)\n",
    "\n",
    "data = data.dropna(subset=['id'])\n",
    "\n",
    "rows_dropped = rows_before - len(data)\n",
    "print(f\"Rows dropped due to missing id: {rows_dropped}\")\n",
    "print(f\"Remaining rows: {len(data)}\")\n",
    "print(f\"Percentage retained: {(len(data)/rows_before)*100:.2f}%\")\n",
    "\n",
    "# Convert id to integer for proper merging\n",
    "data['id'] = data['id'].astype(int)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped due to missing id: 0\n",
      "Remaining rows: 46419\n",
      "Percentage retained: 100.00%\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "# Step 2: Parse JSON column (keywords)"
   ]
  },
  {
   "cell_type": "code",
   "id": "parse_keywords",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:57:09.761117Z",
     "start_time": "2025-10-25T03:57:08.887959Z"
    }
   },
   "source": [
    "def parse_keywords(keywords_str):\n",
    "    \"\"\"\n",
    "    Parse keywords JSON string and extract keyword names.\n",
    "    Returns list of keyword names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(keywords_str):\n",
    "            return []\n",
    "        keywords_list = ast.literal_eval(keywords_str)\n",
    "        return [keyword['name'] for keyword in keywords_list if 'name' in keyword]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Apply parsing function\n",
    "print(\"Parsing keywords...\")\n",
    "data['keywords_list'] = data['keywords'].apply(parse_keywords)\n",
    "\n",
    "print(\"\\n✓ JSON column parsed successfully\")\n",
    "print(\"\\nExample results:\")\n",
    "print(data[['id', 'keywords_list']].head(5))\n",
    "\n",
    "# Show statistics\n",
    "keyword_counts = data['keywords_list'].apply(len)\n",
    "print(f\"\\nKeyword statistics:\")\n",
    "print(f\"  - Average keywords per movie: {keyword_counts.mean():.2f}\")\n",
    "print(f\"  - Median keywords per movie: {keyword_counts.median():.0f}\")\n",
    "print(f\"  - Movies with no keywords: {(keyword_counts == 0).sum()}\")\n",
    "print(f\"  - Movies with keywords: {(keyword_counts > 0).sum()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing keywords...\n",
      "\n",
      "✓ JSON column parsed successfully\n",
      "\n",
      "Example results:\n",
      "      id                                      keywords_list\n",
      "0    862  [jealousy, toy, boy, friendship, friends, riva...\n",
      "1   8844  [board game, disappearance, based on children'...\n",
      "2  15602  [fishing, best friend, duringcreditsstinger, o...\n",
      "3  31357  [based on novel, interracial relationship, sin...\n",
      "4  11862  [baby, midlife crisis, confidence, aging, daug...\n",
      "\n",
      "Keyword statistics:\n",
      "  - Average keywords per movie: 3.42\n",
      "  - Median keywords per movie: 2\n",
      "  - Movies with no keywords: 14795\n",
      "  - Movies with keywords: 31624\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "# Step 3: Verify id exists in cleaned_movies_metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "verify_metadata",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:57:11.374151Z",
     "start_time": "2025-10-25T03:57:11.158589Z"
    }
   },
   "source": [
    "# Load cleaned movies metadata to verify ids\n",
    "movies_metadata = pd.read_csv('../../datasets/output/cleaned_datasets/cleaned_movies_metadata.csv')\n",
    "valid_movie_ids = set(movies_metadata['id'].unique())\n",
    "\n",
    "print(f\"Valid movie IDs in metadata: {len(valid_movie_ids)}\")\n",
    "\n",
    "# Keep only keywords for movies that exist in metadata\n",
    "rows_before_validation = len(data)\n",
    "data = data[data['id'].isin(valid_movie_ids)]\n",
    "\n",
    "rows_dropped = rows_before_validation - len(data)\n",
    "print(f\"Rows dropped (id not in movies_metadata): {rows_dropped}\")\n",
    "print(f\"Remaining rows: {len(data)}\")\n",
    "print(f\"Coverage: {(len(data)/len(valid_movie_ids))*100:.2f}% of movies have keywords data\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid movie IDs in metadata: 45430\n",
      "Rows dropped (id not in movies_metadata): 4\n",
      "Remaining rows: 46415\n",
      "Coverage: 102.17% of movies have keywords data\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "# Step 4: Save cleaned keywords dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "save_dataset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T03:57:12.445384Z",
     "start_time": "2025-10-25T03:57:12.386280Z"
    }
   },
   "source": [
    "# Select relevant columns\n",
    "columns_to_keep = ['id', 'keywords_list']\n",
    "cleaned_data = data[columns_to_keep].copy()\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../../datasets/output/cleaned_datasets/cleaned_keywords.csv'\n",
    "cleaned_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Cleaned keywords dataset saved to: {output_path}\")\n",
    "print(f\"Final dataset: {len(cleaned_data)} rows, {len(cleaned_data.columns)} columns\")\n",
    "print(f\"\\nColumn summary:\")\n",
    "print(f\"  - id: Movie identifier (tmdbId)\")\n",
    "print(f\"  - keywords_list: List of movie keywords/tags\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(cleaned_data.head())\n",
    "\n",
    "# Show some interesting keyword examples\n",
    "print(f\"\\nExamples of movies with many keywords:\")\n",
    "data_with_counts = cleaned_data.copy()\n",
    "data_with_counts['keyword_count'] = data_with_counts['keywords_list'].apply(len)\n",
    "top_keywords = data_with_counts.nlargest(3, 'keyword_count')\n",
    "for idx, row in top_keywords.iterrows():\n",
    "    print(f\"  Movie ID {row['id']}: {row['keyword_count']} keywords\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned keywords dataset saved to: ../../datasets/output/cleaned_datasets/cleaned_keywords.csv\n",
      "Final dataset: 46415 rows, 2 columns\n",
      "\n",
      "Column summary:\n",
      "  - id: Movie identifier (tmdbId)\n",
      "  - keywords_list: List of movie keywords/tags\n",
      "\n",
      "Sample data:\n",
      "      id                                      keywords_list\n",
      "0    862  [jealousy, toy, boy, friendship, friends, riva...\n",
      "1   8844  [board game, disappearance, based on children'...\n",
      "2  15602  [fishing, best friend, duringcreditsstinger, o...\n",
      "3  31357  [based on novel, interracial relationship, sin...\n",
      "4  11862  [baby, midlife crisis, confidence, aging, daug...\n",
      "\n",
      "Examples of movies with many keywords:\n",
      "  Movie ID 23160: 149 keywords\n",
      "  Movie ID 117483: 113 keywords\n",
      "  Movie ID 26390: 97 keywords\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e09b0a6e22e1d9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
