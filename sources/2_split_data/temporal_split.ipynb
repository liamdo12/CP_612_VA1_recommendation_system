{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Temporal Split (80/20) - Method 2\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements **Method 2: Temporal Split** for train/test data preparation.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "- **Approach**: Time-based split - train on past, test on future\n",
    "- **Split Ratio**: 80% training (older ratings), 20% testing (newer ratings)\n",
    "- **Ordering**: Sort by timestamp before splitting\n",
    "\n",
    "### Why Temporal Split is Superior\n",
    "\n",
    "Temporal split better reflects real-world recommendation systems:\n",
    "- ✅ **Realistic evaluation**: Predicts future user behavior from past patterns\n",
    "- ✅ **Prevents temporal leakage**: Never trains on future to predict past\n",
    "- ✅ **Industry standard**: Used by Netflix, Spotify, Amazon\n",
    "- ✅ **Captures dynamics**: Measures adaptation to changing user tastes\n",
    "- ✅ **Reveals cold-start**: Identifies new users/items in test period\n",
    "\n",
    "### Real-World Simulation\n",
    "\n",
    "```\n",
    "Training Period: All ratings from 1996 to ~2015\n",
    "  → Learn user preferences and item patterns\n",
    "  \n",
    "Test Period: All ratings from ~2015 to 2018  \n",
    "  → Predict recent/future ratings based on historical patterns\n",
    "  \n",
    "Question: Can the model recommend movies in 2015-2018\n",
    "         based on patterns learned from 1996-2015?\n",
    "```\n",
    "\n",
    "### Output\n",
    "\n",
    "- `train_ratings.csv`: Training set (older 80% of ratings)\n",
    "- `test_ratings.csv`: Test set (newer 20% of ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## Step 1: Load Cleaned Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "load_data",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:40:02.583979Z",
     "start_time": "2025-10-25T04:39:59.496900Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load cleaned ratings\n",
    "print(\"Loading cleaned ratings dataset...\")\n",
    "ratings = pd.read_csv('../../datasets/output/cleaned_datasets/cleaned_ratings.csv', low_memory=False)\n",
    "\n",
    "print(f\"✓ Dataset loaded successfully\")\n",
    "print(f\"\\nDataset Shape: {ratings.shape}\")\n",
    "print(f\"Columns: {list(ratings.columns)}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(ratings.dtypes)\n",
    "print(f\"\\nSample Data:\")\n",
    "print(ratings.head(10))\n",
    "\n",
    "# Verify timestamp column exists\n",
    "if 'timestamp' not in ratings.columns:\n",
    "    raise ValueError(\"ERROR: timestamp column not found in ratings dataset!\")\n",
    "else:\n",
    "    print(f\"\\n✓ Timestamp column verified\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned ratings dataset...\n",
      "✓ Dataset loaded successfully\n",
      "\n",
      "Dataset Shape: (26024289, 4)\n",
      "Columns: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "\n",
      "Data Types:\n",
      "userId         int64\n",
      "movieId        int64\n",
      "rating       float64\n",
      "timestamp      int64\n",
      "dtype: object\n",
      "\n",
      "Sample Data:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      110     1.0  1425941529\n",
      "1       1      147     4.5  1425942435\n",
      "2       1      858     5.0  1425941523\n",
      "3       1     1221     5.0  1425941546\n",
      "4       1     1246     5.0  1425941556\n",
      "5       1     1968     4.0  1425942148\n",
      "6       1     2762     4.5  1425941300\n",
      "7       1     2918     5.0  1425941593\n",
      "8       1     2959     4.0  1425941601\n",
      "9       1     4226     4.0  1425942228\n",
      "\n",
      "✓ Timestamp column verified\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "explore_header",
   "metadata": {},
   "source": [
    "## Step 2: Analyze Temporal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "id": "analyze_temporal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:40:20.550769Z",
     "start_time": "2025-10-25T04:40:16.425756Z"
    }
   },
   "source": [
    "# Convert Unix timestamp to datetime\n",
    "print(\"Analyzing temporal distribution...\\n\")\n",
    "\n",
    "ratings['datetime'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "ratings['year'] = ratings['datetime'].dt.year\n",
    "ratings['month'] = ratings['datetime'].dt.to_period('M')\n",
    "\n",
    "# Display temporal range\n",
    "print(f\"Temporal Range:\")\n",
    "print(f\"  - Earliest rating: {ratings['datetime'].min()}\")\n",
    "print(f\"  - Latest rating: {ratings['datetime'].max()}\")\n",
    "print(f\"  - Time span: {(ratings['datetime'].max() - ratings['datetime'].min()).days} days\")\n",
    "\n",
    "# Ratings by year\n",
    "print(f\"\\nRatings by Year:\")\n",
    "year_counts = ratings['year'].value_counts().sort_index()\n",
    "print(year_counts)\n",
    "\n",
    "# Calculate 80% split point\n",
    "split_idx = int(len(ratings) * 0.8)\n",
    "ratings_sorted = ratings.sort_values('timestamp')\n",
    "split_timestamp = ratings_sorted.iloc[split_idx]['timestamp']\n",
    "split_datetime = pd.to_datetime(split_timestamp, unit='s')\n",
    "\n",
    "print(f\"\\n80/20 Split Point:\")\n",
    "print(f\"  - Split at index: {split_idx:,}\")\n",
    "print(f\"  - Split timestamp: {split_timestamp}\")\n",
    "print(f\"  - Split date: {split_datetime}\")\n",
    "print(f\"\\nTraining period: {ratings_sorted['datetime'].min()} to {split_datetime}\")\n",
    "print(f\"Test period: {split_datetime} to {ratings_sorted['datetime'].max()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing temporal distribution...\n",
      "\n",
      "Temporal Range:\n",
      "  - Earliest rating: 1995-01-09 11:46:44\n",
      "  - Latest rating: 2017-08-04 06:57:50\n",
      "  - Time span: 8242 days\n",
      "\n",
      "Ratings by Year:\n",
      "year\n",
      "1995          4\n",
      "1996    1733263\n",
      "1997     763932\n",
      "1998     329720\n",
      "1999    1231263\n",
      "2000    2034030\n",
      "2001    1239718\n",
      "2002     910659\n",
      "2003    1079511\n",
      "2004    1202081\n",
      "2005    1850589\n",
      "2006    1211577\n",
      "2007    1096103\n",
      "2008    1211067\n",
      "2009     993934\n",
      "2010     983023\n",
      "2011     835260\n",
      "2012     793710\n",
      "2013     634778\n",
      "2014     586094\n",
      "2015    1913720\n",
      "2016    2094961\n",
      "2017    1295292\n",
      "Name: count, dtype: int64\n",
      "\n",
      "80/20 Split Point:\n",
      "  - Split at index: 20,819,431\n",
      "  - Split timestamp: 1422580677\n",
      "  - Split date: 2015-01-30 01:17:57\n",
      "\n",
      "Training period: 1995-01-09 11:46:44 to 2015-01-30 01:17:57\n",
      "Test period: 2015-01-30 01:17:57 to 2017-08-04 06:57:50\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "visualize_header",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Temporal Patterns (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "id": "visualize_temporal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:40:28.488807Z",
     "start_time": "2025-10-25T04:40:27.724174Z"
    }
   },
   "source": [
    "# Display ratings distribution over time\n",
    "print(\"Ratings Distribution by Year:\\n\")\n",
    "\n",
    "year_stats = ratings.groupby('year').agg({\n",
    "    'rating': ['count', 'mean'],\n",
    "    'userId': 'nunique',\n",
    "    'movieId': 'nunique'\n",
    "})\n",
    "year_stats.columns = ['Total Ratings', 'Avg Rating', 'Unique Users', 'Unique Movies']\n",
    "print(year_stats)\n",
    "\n",
    "# Identify split year\n",
    "split_year = split_datetime.year\n",
    "print(f\"\\n✓ Split occurs in year: {split_year}\")\n",
    "print(f\"Training data: Up to {split_datetime.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Test data: From {split_datetime.strftime('%Y-%m-%d')} onwards\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Distribution by Year:\n",
      "\n",
      "      Total Ratings  Avg Rating  Unique Users  Unique Movies\n",
      "year                                                        \n",
      "1995              4    3.750000             2              4\n",
      "1996        1733263    3.554189         34448           1392\n",
      "1997         763932    3.592388         16768           1679\n",
      "1998         329720    3.522659          6880           2309\n",
      "1999        1231263    3.617325         14223           3054\n",
      "2000        2034030    3.577626         25358           3934\n",
      "2001        1239718    3.535594         16430           4848\n",
      "2002         910659    3.484433         11661           5805\n",
      "2003        1079511    3.471338         11899           6873\n",
      "2004        1202081    3.426694         10829           8032\n",
      "2005        1850589    3.431955         15616           8512\n",
      "2006        1211577    3.459998         12975           8844\n",
      "2007        1096103    3.463976         13044           9383\n",
      "2008        1211067    3.527408         15182          10110\n",
      "2009         993934    3.490686         15051          12031\n",
      "2010         983023    3.510295         16408          13804\n",
      "2011         835260    3.535955         15336          14999\n",
      "2012         793710    3.585694         14190          15300\n",
      "2013         634778    3.626040         11871          16098\n",
      "2014         586094    3.595565         10383          17143\n",
      "2015        1913720    3.574813         23333          27556\n",
      "2016        2094961    3.536960         21178          33525\n",
      "2017        1295292    3.554788         14075          29873\n",
      "\n",
      "✓ Split occurs in year: 2015\n",
      "Training data: Up to 2015-01-30\n",
      "Test data: From 2015-01-30 onwards\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "split_header",
   "metadata": {},
   "source": [
    "## Step 4: Perform Temporal Split"
   ]
  },
  {
   "cell_type": "code",
   "id": "perform_split",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:40:34.897284Z",
     "start_time": "2025-10-25T04:40:32.287200Z"
    }
   },
   "source": [
    "# Sort by timestamp (critical for temporal split!)\n",
    "print(\"Performing temporal 80/20 train/test split...\\n\")\n",
    "print(\"Step 1: Sorting by timestamp...\")\n",
    "\n",
    "ratings_sorted = ratings.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Sorted {len(ratings_sorted):,} ratings by timestamp\")\n",
    "\n",
    "# Perform split\n",
    "print(\"\\nStep 2: Splitting at 80% mark...\")\n",
    "split_idx = int(len(ratings_sorted) * 0.8)\n",
    "\n",
    "train = ratings_sorted.iloc[:split_idx].copy()\n",
    "test = ratings_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"\\n✓ Split completed successfully\\n\")\n",
    "\n",
    "# Display split statistics\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  - Rows: {len(train):,} ({len(train)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Temporal range: {train['datetime'].min()} to {train['datetime'].max()}\")\n",
    "print(f\"  - Users: {train['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {train['movieId'].nunique():,}\")\n",
    "print(f\"  - Avg rating: {train['rating'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  - Rows: {len(test):,} ({len(test)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Temporal range: {test['datetime'].min()} to {test['datetime'].max()}\")\n",
    "print(f\"  - Users: {test['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {test['movieId'].nunique():,}\")\n",
    "print(f\"  - Avg rating: {test['rating'].mean():.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing temporal 80/20 train/test split...\n",
      "\n",
      "Step 1: Sorting by timestamp...\n",
      "✓ Sorted 26,024,289 ratings by timestamp\n",
      "\n",
      "Step 2: Splitting at 80% mark...\n",
      "\n",
      "✓ Split completed successfully\n",
      "\n",
      "Training Set:\n",
      "  - Rows: 20,819,431 (80.00%)\n",
      "  - Temporal range: 1995-01-09 11:46:44 to 2015-01-30 01:17:56\n",
      "  - Users: 227,222\n",
      "  - Movies: 25,636\n",
      "  - Avg rating: 3.5210\n",
      "\n",
      "Test Set:\n",
      "  - Rows: 5,204,858 (20.00%)\n",
      "  - Temporal range: 2015-01-30 01:17:57 to 2017-08-04 06:57:50\n",
      "  - Users: 48,464\n",
      "  - Movies: 42,721\n",
      "  - Avg rating: 3.5566\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "validate_header",
   "metadata": {},
   "source": [
    "## Step 5: Validate Temporal Ordering"
   ]
  },
  {
   "cell_type": "code",
   "id": "validate_temporal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:40:55.048657Z",
     "start_time": "2025-10-25T04:40:53.986003Z"
    }
   },
   "source": [
    "print(\"Validating temporal split integrity...\\n\")\n",
    "\n",
    "# Check 1: Strict temporal ordering (all train timestamps < all test timestamps)\n",
    "max_train_timestamp = train['timestamp'].max()\n",
    "min_test_timestamp = test['timestamp'].min()\n",
    "\n",
    "print(f\"Check 1: Temporal ordering\")\n",
    "print(f\"  - Latest train timestamp: {pd.to_datetime(max_train_timestamp, unit='s')}\")\n",
    "print(f\"  - Earliest test timestamp: {pd.to_datetime(min_test_timestamp, unit='s')}\")\n",
    "print(f\"  - Max train < Min test: {max_train_timestamp < min_test_timestamp}\")\n",
    "\n",
    "# Note: Temporal split may have overlap at boundary (ratings with same timestamp)\n",
    "# This is acceptable and reflects real-world scenarios\n",
    "if max_train_timestamp >= min_test_timestamp:\n",
    "    overlap_count = len(train[train['timestamp'] == max_train_timestamp])\n",
    "    print(f\"  ⚠️  Boundary overlap: {overlap_count} ratings share the split timestamp\")\n",
    "    print(f\"      This is normal and acceptable for temporal splits\")\n",
    "else:\n",
    "    print(f\"  ✓ PASS - Perfect temporal separation\")\n",
    "\n",
    "# Check 2: No index overlap\n",
    "train_indices = set(train.index)\n",
    "test_indices = set(test.index)\n",
    "overlap = train_indices.intersection(test_indices)\n",
    "\n",
    "print(f\"\\nCheck 2: No row overlap\")\n",
    "print(f\"  - Train indices: {len(train_indices):,}\")\n",
    "print(f\"  - Test indices: {len(test_indices):,}\")\n",
    "print(f\"  - Overlap: {len(overlap)} {'✓ PASS' if len(overlap) == 0 else '✗ FAIL'}\")\n",
    "\n",
    "# Check 3: Verify proportions\n",
    "train_pct = len(train) / len(ratings) * 100\n",
    "test_pct = len(test) / len(ratings) * 100\n",
    "total_pct = train_pct + test_pct\n",
    "\n",
    "print(f\"\\nCheck 3: Verify 80/20 proportions\")\n",
    "print(f\"  - Train: {train_pct:.2f}% (expected ~80%)\")\n",
    "print(f\"  - Test: {test_pct:.2f}% (expected ~20%)\")\n",
    "print(f\"  - Total: {total_pct:.2f}% (expected 100%)\")\n",
    "print(f\"  - {'✓ PASS' if 79.5 <= train_pct <= 80.5 and 19.5 <= test_pct <= 20.5 else '✗ FAIL'}\")\n",
    "\n",
    "# Check 4: All columns preserved\n",
    "print(f\"\\nCheck 4: All columns preserved\")\n",
    "print(f\"  - Original columns: {len(ratings.columns)}\")\n",
    "print(f\"  - Train columns: {len(train.columns)}\")\n",
    "print(f\"  - Test columns: {len(test.columns)}\")\n",
    "print(f\"  - {'✓ PASS' if len(train.columns) == len(test.columns) == len(ratings.columns) else '✗ FAIL'}\")\n",
    "\n",
    "# Check 5: Rating distribution comparison\n",
    "print(f\"\\nCheck 5: Rating distribution comparison\")\n",
    "print(f\"\\nTrain distribution:\")\n",
    "train_dist = train['rating'].value_counts(normalize=True).sort_index() * 100\n",
    "print(train_dist.to_string())\n",
    "\n",
    "print(f\"\\nTest distribution:\")\n",
    "test_dist = test['rating'].value_counts(normalize=True).sort_index() * 100\n",
    "print(test_dist.to_string())\n",
    "\n",
    "print(f\"\\n✓ All validation checks completed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating temporal split integrity...\n",
      "\n",
      "Check 1: Temporal ordering\n",
      "  - Latest train timestamp: 2015-01-30 01:17:56\n",
      "  - Earliest test timestamp: 2015-01-30 01:17:57\n",
      "  - Max train < Min test: True\n",
      "  ✓ PASS - Perfect temporal separation\n",
      "\n",
      "Check 2: No row overlap\n",
      "  - Train indices: 20,819,431\n",
      "  - Test indices: 5,204,858\n",
      "  - Overlap: 0 ✓ PASS\n",
      "\n",
      "Check 3: Verify 80/20 proportions\n",
      "  - Train: 80.00% (expected ~80%)\n",
      "  - Test: 20.00% (expected ~20%)\n",
      "  - Total: 100.00% (expected 100%)\n",
      "  - ✓ PASS\n",
      "\n",
      "Check 4: All columns preserved\n",
      "  - Original columns: 7\n",
      "  - Train columns: 7\n",
      "  - Test columns: 7\n",
      "  - ✓ PASS\n",
      "\n",
      "Check 5: Rating distribution comparison\n",
      "\n",
      "Train distribution:\n",
      "rating\n",
      "0.5     1.255193\n",
      "1.0     3.471853\n",
      "1.5     1.424693\n",
      "2.0     7.204083\n",
      "2.5     4.395034\n",
      "3.0    21.515521\n",
      "3.5    10.831309\n",
      "4.0    27.729495\n",
      "4.5     7.549313\n",
      "5.0    14.623507\n",
      "\n",
      "Test distribution:\n",
      "rating\n",
      "0.5     2.758442\n",
      "1.0     2.314953\n",
      "1.5     2.055656\n",
      "2.0     5.045114\n",
      "2.5     6.538834\n",
      "3.0    14.934375\n",
      "3.5    16.546004\n",
      "4.0    23.548750\n",
      "4.5    11.503042\n",
      "5.0    14.754831\n",
      "\n",
      "✓ All validation checks completed\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "coldstart_header",
   "metadata": {},
   "source": [
    "## Step 6: Cold-Start Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "coldstart_analysis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:41:11.219839Z",
     "start_time": "2025-10-25T04:41:10.657984Z"
    }
   },
   "source": [
    "print(\"Analyzing cold-start scenarios...\\n\")\n",
    "\n",
    "# User overlap analysis\n",
    "train_users = set(train['userId'].unique())\n",
    "test_users = set(test['userId'].unique())\n",
    "\n",
    "common_users = train_users.intersection(test_users)\n",
    "new_users_in_test = test_users - train_users\n",
    "users_only_in_train = train_users - test_users\n",
    "\n",
    "print(f\"User Analysis:\")\n",
    "print(f\"  - Train users: {len(train_users):,}\")\n",
    "print(f\"  - Test users: {len(test_users):,}\")\n",
    "print(f\"  - Common users (in both): {len(common_users):,} ({len(common_users)/len(test_users)*100:.2f}% of test)\")\n",
    "print(f\"  - NEW users in test (cold-start): {len(new_users_in_test):,} ({len(new_users_in_test)/len(test_users)*100:.2f}% of test)\")\n",
    "print(f\"  - Users only in train: {len(users_only_in_train):,}\")\n",
    "\n",
    "# Movie overlap analysis  \n",
    "train_movies = set(train['movieId'].unique())\n",
    "test_movies = set(test['movieId'].unique())\n",
    "\n",
    "common_movies = train_movies.intersection(test_movies)\n",
    "new_movies_in_test = test_movies - train_movies\n",
    "movies_only_in_train = train_movies - test_movies\n",
    "\n",
    "print(f\"\\nMovie Analysis:\")\n",
    "print(f\"  - Train movies: {len(train_movies):,}\")\n",
    "print(f\"  - Test movies: {len(test_movies):,}\")\n",
    "print(f\"  - Common movies (in both): {len(common_movies):,} ({len(common_movies)/len(test_movies)*100:.2f}% of test)\")\n",
    "print(f\"  - NEW movies in test (cold-start): {len(new_movies_in_test):,} ({len(new_movies_in_test)/len(test_movies)*100:.2f}% of test)\")\n",
    "print(f\"  - Movies only in train: {len(movies_only_in_train):,}\")\n",
    "\n",
    "# Cold-start impact on test ratings\n",
    "test_coldstart_users = test[test['userId'].isin(new_users_in_test)]\n",
    "test_coldstart_movies = test[test['movieId'].isin(new_movies_in_test)]\n",
    "\n",
    "print(f\"\\nCold-Start Impact on Test Set:\")\n",
    "print(f\"  - Ratings from NEW users: {len(test_coldstart_users):,} ({len(test_coldstart_users)/len(test)*100:.2f}% of test)\")\n",
    "print(f\"  - Ratings for NEW movies: {len(test_coldstart_movies):,} ({len(test_coldstart_movies)/len(test)*100:.2f}% of test)\")\n",
    "\n",
    "print(f\"\\n✓ Cold-start analysis completed\")\n",
    "print(f\"\\nNote: Cold-start items/users are realistic in temporal splits.\")\n",
    "print(f\"They represent new users/movies appearing in the test period.\")\n",
    "print(f\"This reflects production scenarios where the model must handle new entities.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing cold-start scenarios...\n",
      "\n",
      "User Analysis:\n",
      "  - Train users: 227,222\n",
      "  - Test users: 48,464\n",
      "  - Common users (in both): 4,790 (9.88% of test)\n",
      "  - NEW users in test (cold-start): 43,674 (90.12% of test)\n",
      "  - Users only in train: 222,432\n",
      "\n",
      "Movie Analysis:\n",
      "  - Train movies: 25,636\n",
      "  - Test movies: 42,721\n",
      "  - Common movies (in both): 23,242 (54.40% of test)\n",
      "  - NEW movies in test (cold-start): 19,479 (45.60% of test)\n",
      "  - Movies only in train: 2,394\n",
      "\n",
      "Cold-Start Impact on Test Set:\n",
      "  - Ratings from NEW users: 4,645,394 (89.25% of test)\n",
      "  - Ratings for NEW movies: 401,578 (7.72% of test)\n",
      "\n",
      "✓ Cold-start analysis completed\n",
      "\n",
      "Note: Cold-start items/users are realistic in temporal splits.\n",
      "They represent new users/movies appearing in the test period.\n",
      "This reflects production scenarios where the model must handle new entities.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "save_header",
   "metadata": {},
   "source": [
    "## Step 7: Save Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "save_datasets",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:41:34.873545Z",
     "start_time": "2025-10-25T04:41:19.025977Z"
    }
   },
   "source": [
    "# Remove temporary datetime columns before saving\n",
    "columns_to_save = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "\n",
    "train_final = train[columns_to_save].copy()\n",
    "test_final = test[columns_to_save].copy()\n",
    "\n",
    "# Define output paths\n",
    "output_dir = '../../datasets/output/split_and_train_datasets/temporal_split/'\n",
    "train_path = output_dir + 'train_ratings.csv'\n",
    "test_path = output_dir + 'test_ratings.csv'\n",
    "\n",
    "# Save datasets\n",
    "print(\"Saving train and test datasets...\\n\")\n",
    "\n",
    "print(f\"Saving training set to: {train_path}\")\n",
    "train_final.to_csv(train_path, index=False)\n",
    "print(f\"✓ Training set saved ({len(train_final):,} rows)\")\n",
    "\n",
    "print(f\"\\nSaving test set to: {test_path}\")\n",
    "test_final.to_csv(test_path, index=False)\n",
    "print(f\"✓ Test set saved ({len(test_final):,} rows)\")\n",
    "\n",
    "# Verify files were created\n",
    "import os\n",
    "print(f\"\\nVerifying saved files:\")\n",
    "train_size_mb = os.path.getsize(train_path) / (1024 * 1024)\n",
    "test_size_mb = os.path.getsize(test_path) / (1024 * 1024)\n",
    "print(f\"  - {train_path}\")\n",
    "print(f\"    Size: {train_size_mb:.2f} MB\")\n",
    "print(f\"    Temporal range: {train['datetime'].min()} to {train['datetime'].max()}\")\n",
    "print(f\"  - {test_path}\")\n",
    "print(f\"    Size: {test_size_mb:.2f} MB\")\n",
    "print(f\"    Temporal range: {test['datetime'].min()} to {test['datetime'].max()}\")\n",
    "\n",
    "print(f\"\\n✓ All files saved successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train and test datasets...\n",
      "\n",
      "Saving training set to: ../../datasets/output/split_and_train_datasets/temporal_split/train_ratings.csv\n",
      "✓ Training set saved (20,819,431 rows)\n",
      "\n",
      "Saving test set to: ../../datasets/output/split_and_train_datasets/temporal_split/test_ratings.csv\n",
      "✓ Test set saved (5,204,858 rows)\n",
      "\n",
      "Verifying saved files:\n",
      "  - ../../datasets/output/split_and_train_datasets/temporal_split/train_ratings.csv\n",
      "    Size: 517.09 MB\n",
      "    Temporal range: 1995-01-09 11:46:44 to 2015-01-30 01:17:56\n",
      "  - ../../datasets/output/split_and_train_datasets/temporal_split/test_ratings.csv\n",
      "    Size: 134.77 MB\n",
      "    Temporal range: 2015-01-30 01:17:57 to 2017-08-04 06:57:50\n",
      "\n",
      "✓ All files saved successfully\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Temporal Split (80/20) Completed\n",
    "\n",
    "**Method**: Time-based split - training on past ratings, testing on future ratings\n",
    "\n",
    "**Output Files**:\n",
    "- `train_ratings.csv`: Training set (older 80% of ratings)\n",
    "- `test_ratings.csv`: Test set (newer 20% of ratings)\n",
    "\n",
    "**Key Characteristics**:\n",
    "- Strict temporal ordering (train timestamps < test timestamps)\n",
    "- No data leakage (no future information in training)\n",
    "- Preserved all columns\n",
    "- Realistic cold-start scenarios included\n",
    "\n",
    "**Advantages Over Random Split**:\n",
    "- ✅ Simulates real-world deployment (predict future from past)\n",
    "- ✅ Prevents temporal leakage (never trains on future to predict past)\n",
    "- ✅ Reveals model's ability to handle new users/items\n",
    "- ✅ Industry standard evaluation method\n",
    "- ✅ More honest/conservative performance estimates\n",
    "\n",
    "**Next Steps**:\n",
    "1. Use `train_ratings.csv` for model training (collaborative filtering)\n",
    "2. Use `test_ratings.csv` for evaluation (RMSE, MAE, Precision@K)\n",
    "3. Compare with random split to demonstrate temporal split benefits\n",
    "4. Address cold-start challenges in \"Improvement Opportunities\" section"
   ]
  },
  {
   "cell_type": "code",
   "id": "final_stats",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:41:38.057041Z",
     "start_time": "2025-10-25T04:41:37.855647Z"
    }
   },
   "source": [
    "# Final summary statistics\n",
    "print(\"=\"*70)\n",
    "print(\"TEMPORAL SPLIT (80/20) - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOriginal Dataset: {len(ratings):,} ratings\")\n",
    "print(f\"Temporal Range: {ratings['datetime'].min()} to {ratings['datetime'].max()}\")\n",
    "\n",
    "print(f\"\\nTraining Set: {len(train_final):,} ratings ({len(train_final)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Period: {train['datetime'].min()} to {train['datetime'].max()}\")\n",
    "print(f\"  - Users: {train['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {train['movieId'].nunique():,}\")\n",
    "print(f\"  - Avg rating: {train['rating'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set: {len(test_final):,} ratings ({len(test_final)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Period: {test['datetime'].min()} to {test['datetime'].max()}\")\n",
    "print(f\"  - Users: {test['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {test['movieId'].nunique():,}\")\n",
    "print(f\"  - Avg rating: {test['rating'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nCold-Start Statistics:\")\n",
    "print(f\"  - New users in test: {len(new_users_in_test):,} ({len(new_users_in_test)/len(test_users)*100:.2f}% of test users)\")\n",
    "print(f\"  - New movies in test: {len(new_movies_in_test):,} ({len(new_movies_in_test)/len(test_movies)*100:.2f}% of test movies)\")\n",
    "\n",
    "print(f\"\\nOutput Location: {output_dir}\")\n",
    "print(f\"  - train_ratings.csv ({train_size_mb:.2f} MB)\")\n",
    "print(f\"  - test_ratings.csv ({test_size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Temporal split completed successfully\")\n",
    "print(\"✓ Data ready for time-aware model evaluation\")\n",
    "print(\"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEMPORAL SPLIT (80/20) - FINAL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Original Dataset: 26,024,289 ratings\n",
      "Temporal Range: 1995-01-09 11:46:44 to 2017-08-04 06:57:50\n",
      "\n",
      "Training Set: 20,819,431 ratings (80.00%)\n",
      "  - Period: 1995-01-09 11:46:44 to 2015-01-30 01:17:56\n",
      "  - Users: 227,222\n",
      "  - Movies: 25,636\n",
      "  - Avg rating: 3.5210\n",
      "\n",
      "Test Set: 5,204,858 ratings (20.00%)\n",
      "  - Period: 2015-01-30 01:17:57 to 2017-08-04 06:57:50\n",
      "  - Users: 48,464\n",
      "  - Movies: 42,721\n",
      "  - Avg rating: 3.5566\n",
      "\n",
      "Cold-Start Statistics:\n",
      "  - New users in test: 43,674 (90.12% of test users)\n",
      "  - New movies in test: 19,479 (45.60% of test movies)\n",
      "\n",
      "Output Location: ../../datasets/output/split_and_train_datasets/temporal_split/\n",
      "  - train_ratings.csv (517.09 MB)\n",
      "  - test_ratings.csv (134.77 MB)\n",
      "\n",
      "======================================================================\n",
      "✓ Temporal split completed successfully\n",
      "✓ Data ready for time-aware model evaluation\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e612521dadf58b75"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
