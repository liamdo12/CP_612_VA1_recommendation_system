{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Random Split (80/20) - Method 1\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements **Method 1: Random Split** for train/test data preparation.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "- **Approach**: Random sampling without considering temporal order\n",
    "- **Split Ratio**: 80% training, 20% testing\n",
    "- **Random State**: 42 (for reproducibility)\n",
    "\n",
    "### Use Case\n",
    "\n",
    "Random split is a baseline approach that:\n",
    "- ✅ Ensures even distribution across users/movies\n",
    "- ✅ Simple to implement and understand\n",
    "- ✅ Standard approach for initial model development\n",
    "- ⚠️ Does not reflect real-world temporal deployment\n",
    "\n",
    "### Output\n",
    "\n",
    "- `train_ratings.csv`: Training set (~80% of data)\n",
    "- `test_ratings.csv`: Test set (~20% of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "## Step 1: Load Cleaned Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "load_data",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:20:33.884260Z",
     "start_time": "2025-10-25T04:20:29.958531Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load cleaned ratings\n",
    "print(\"Loading cleaned ratings dataset...\")\n",
    "ratings = pd.read_csv('../../datasets/output/cleaned_datasets/cleaned_ratings.csv', low_memory=False)\n",
    "\n",
    "print(f\"✓ Dataset loaded successfully\")\n",
    "print(f\"\\nDataset Shape: {ratings.shape}\")\n",
    "print(f\"Columns: {list(ratings.columns)}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(ratings.dtypes)\n",
    "print(f\"\\nSample Data:\")\n",
    "print(ratings.head(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned ratings dataset...\n",
      "✓ Dataset loaded successfully\n",
      "\n",
      "Dataset Shape: (26024289, 4)\n",
      "Columns: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "\n",
      "Data Types:\n",
      "userId         int64\n",
      "movieId        int64\n",
      "rating       float64\n",
      "timestamp      int64\n",
      "dtype: object\n",
      "\n",
      "Sample Data:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      110     1.0  1425941529\n",
      "1       1      147     4.5  1425942435\n",
      "2       1      858     5.0  1425941523\n",
      "3       1     1221     5.0  1425941546\n",
      "4       1     1246     5.0  1425941556\n",
      "5       1     1968     4.0  1425942148\n",
      "6       1     2762     4.5  1425941300\n",
      "7       1     2918     5.0  1425941593\n",
      "8       1     2959     4.0  1425941601\n",
      "9       1     4226     4.0  1425942228\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "explore_header",
   "metadata": {},
   "source": [
    "## Step 2: Explore Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "id": "explore_data",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:20:36.450111Z",
     "start_time": "2025-10-25T04:20:35.893350Z"
    }
   },
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\\n\")\n",
    "print(f\"Total Ratings: {len(ratings):,}\")\n",
    "print(f\"Unique Users: {ratings['userId'].nunique():,}\")\n",
    "print(f\"Unique Movies: {ratings['movieId'].nunique():,}\")\n",
    "print(f\"\\nRating Distribution:\")\n",
    "print(ratings['rating'].value_counts().sort_index())\n",
    "print(f\"\\nRating Statistics:\")\n",
    "print(ratings['rating'].describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "\n",
      "Total Ratings: 26,024,289\n",
      "Unique Users: 270,896\n",
      "Unique Movies: 45,115\n",
      "\n",
      "Rating Distribution:\n",
      "rating\n",
      "0.5     404897\n",
      "1.0     843310\n",
      "1.5     403607\n",
      "2.0    1762440\n",
      "2.5    1255358\n",
      "3.0    5256722\n",
      "3.5    3116213\n",
      "4.0    6998802\n",
      "4.5    2170441\n",
      "5.0    3812499\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rating Statistics:\n",
      "count    2.602429e+07\n",
      "mean     3.528090e+00\n",
      "std      1.065443e+00\n",
      "min      5.000000e-01\n",
      "25%      3.000000e+00\n",
      "50%      3.500000e+00\n",
      "75%      4.000000e+00\n",
      "max      5.000000e+00\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "split_header",
   "metadata": {},
   "source": [
    "## Step 3: Perform Random 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "id": "perform_split",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:20:41.252730Z",
     "start_time": "2025-10-25T04:20:40.052758Z"
    }
   },
   "source": [
    "# Perform random split\n",
    "print(\"Performing random 80/20 train/test split...\\n\")\n",
    "\n",
    "train, test = train_test_split(\n",
    "    ratings,\n",
    "    test_size=0.2,      # 20% for test\n",
    "    random_state=42,    # For reproducibility\n",
    "    shuffle=True        # Ensure random sampling\n",
    ")\n",
    "\n",
    "print(\"✓ Split completed successfully\\n\")\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  - Rows: {len(train):,} ({len(train)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Users: {train['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {train['movieId'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  - Rows: {len(test):,} ({len(test)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Users: {test['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {test['movieId'].nunique():,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing random 80/20 train/test split...\n",
      "\n",
      "✓ Split completed successfully\n",
      "\n",
      "Training Set:\n",
      "  - Rows: 20,819,431 (80.00%)\n",
      "  - Users: 269,710\n",
      "  - Movies: 43,326\n",
      "\n",
      "Test Set:\n",
      "  - Rows: 5,204,858 (20.00%)\n",
      "  - Users: 253,107\n",
      "  - Movies: 31,629\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "validate_header",
   "metadata": {},
   "source": [
    "## Step 4: Validate Split Integrity"
   ]
  },
  {
   "cell_type": "code",
   "id": "validate_split",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:21:04.527118Z",
     "start_time": "2025-10-25T04:21:00.209576Z"
    }
   },
   "source": [
    "print(\"Validating split integrity...\\n\")\n",
    "\n",
    "# Check 1: No overlap between train and test indices\n",
    "train_indices = set(train.index)\n",
    "test_indices = set(test.index)\n",
    "overlap = train_indices.intersection(test_indices)\n",
    "\n",
    "print(f\"Check 1: No row overlap\")\n",
    "print(f\"  - Train indices: {len(train_indices):,}\")\n",
    "print(f\"  - Test indices: {len(test_indices):,}\")\n",
    "print(f\"  - Overlap: {len(overlap)} {'✓ PASS' if len(overlap) == 0 else '✗ FAIL'}\")\n",
    "\n",
    "# Check 2: Verify proportions\n",
    "train_pct = len(train) / len(ratings) * 100\n",
    "test_pct = len(test) / len(ratings) * 100\n",
    "total_pct = train_pct + test_pct\n",
    "\n",
    "print(f\"\\nCheck 2: Verify 80/20 proportions\")\n",
    "print(f\"  - Train: {train_pct:.2f}% (expected ~80%)\")\n",
    "print(f\"  - Test: {test_pct:.2f}% (expected ~20%)\")\n",
    "print(f\"  - Total: {total_pct:.2f}% (expected 100%)\")\n",
    "print(f\"  - {'✓ PASS' if 79.5 <= train_pct <= 80.5 and 19.5 <= test_pct <= 20.5 else '✗ FAIL'}\")\n",
    "\n",
    "# Check 3: All columns preserved\n",
    "print(f\"\\nCheck 3: All columns preserved\")\n",
    "print(f\"  - Original columns: {list(ratings.columns)}\")\n",
    "print(f\"  - Train columns: {list(train.columns)}\")\n",
    "print(f\"  - Test columns: {list(test.columns)}\")\n",
    "print(f\"  - {'✓ PASS' if list(train.columns) == list(test.columns) == list(ratings.columns) else '✗ FAIL'}\")\n",
    "\n",
    "# Check 4: Rating distribution similarity\n",
    "print(f\"\\nCheck 4: Rating distribution comparison\")\n",
    "print(f\"\\nOriginal distribution:\")\n",
    "original_dist = ratings['rating'].value_counts(normalize=True).sort_index() * 100\n",
    "print(original_dist.to_string())\n",
    "\n",
    "print(f\"\\nTrain distribution:\")\n",
    "train_dist = train['rating'].value_counts(normalize=True).sort_index() * 100\n",
    "print(train_dist.to_string())\n",
    "\n",
    "print(f\"\\nTest distribution:\")\n",
    "test_dist = test['rating'].value_counts(normalize=True).sort_index() * 100\n",
    "print(test_dist.to_string())\n",
    "\n",
    "print(f\"\\n✓ All validation checks completed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating split integrity...\n",
      "\n",
      "Check 1: No row overlap\n",
      "  - Train indices: 20,819,431\n",
      "  - Test indices: 5,204,858\n",
      "  - Overlap: 0 ✓ PASS\n",
      "\n",
      "Check 2: Verify 80/20 proportions\n",
      "  - Train: 80.00% (expected ~80%)\n",
      "  - Test: 20.00% (expected ~20%)\n",
      "  - Total: 100.00% (expected 100%)\n",
      "  - ✓ PASS\n",
      "\n",
      "Check 3: All columns preserved\n",
      "  - Original columns: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "  - Train columns: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "  - Test columns: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "  - ✓ PASS\n",
      "\n",
      "Check 4: Rating distribution comparison\n",
      "\n",
      "Original distribution:\n",
      "rating\n",
      "0.5     1.555843\n",
      "1.0     3.240473\n",
      "1.5     1.550886\n",
      "2.0     6.772289\n",
      "2.5     4.823794\n",
      "3.0    20.199292\n",
      "3.5    11.974248\n",
      "4.0    26.893346\n",
      "4.5     8.340059\n",
      "5.0    14.649772\n",
      "\n",
      "Train distribution:\n",
      "rating\n",
      "0.5     1.555153\n",
      "1.0     3.240651\n",
      "1.5     1.549586\n",
      "2.0     6.775910\n",
      "2.5     4.820569\n",
      "3.0    20.196426\n",
      "3.5    11.978132\n",
      "4.0    26.891700\n",
      "4.5     8.339594\n",
      "5.0    14.652278\n",
      "\n",
      "Test distribution:\n",
      "rating\n",
      "0.5     1.558602\n",
      "1.0     3.239762\n",
      "1.5     1.556085\n",
      "2.0     6.757802\n",
      "2.5     4.836693\n",
      "3.0    20.210753\n",
      "3.5    11.958712\n",
      "4.0    26.899927\n",
      "4.5     8.341918\n",
      "5.0    14.639746\n",
      "\n",
      "✓ All validation checks completed\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "save_header",
   "metadata": {},
   "source": [
    "## Step 5: Save Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "save_datasets",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:21:27.406739Z",
     "start_time": "2025-10-25T04:21:10.704533Z"
    }
   },
   "source": [
    "# Define output paths\n",
    "output_dir = '../../datasets/output/split_and_train_datasets/80-20/'\n",
    "train_path = output_dir + 'train_ratings.csv'\n",
    "test_path = output_dir + 'test_ratings.csv'\n",
    "\n",
    "# Save datasets\n",
    "print(\"Saving train and test datasets...\\n\")\n",
    "\n",
    "print(f\"Saving training set to: {train_path}\")\n",
    "train.to_csv(train_path, index=False)\n",
    "print(f\"✓ Training set saved ({len(train):,} rows)\")\n",
    "\n",
    "print(f\"\\nSaving test set to: {test_path}\")\n",
    "test.to_csv(test_path, index=False)\n",
    "print(f\"✓ Test set saved ({len(test):,} rows)\")\n",
    "\n",
    "# Verify files were created\n",
    "import os\n",
    "print(f\"\\nVerifying saved files:\")\n",
    "train_size_mb = os.path.getsize(train_path) / (1024 * 1024)\n",
    "test_size_mb = os.path.getsize(test_path) / (1024 * 1024)\n",
    "print(f\"  - {train_path}\")\n",
    "print(f\"    Size: {train_size_mb:.2f} MB\")\n",
    "print(f\"  - {test_path}\")\n",
    "print(f\"    Size: {test_size_mb:.2f} MB\")\n",
    "\n",
    "print(f\"\\n✓ All files saved successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train and test datasets...\n",
      "\n",
      "Saving training set to: ../../datasets/output/split_and_train_datasets/80-20/train_ratings.csv\n",
      "✓ Training set saved (20,819,431 rows)\n",
      "\n",
      "Saving test set to: ../../datasets/output/split_and_train_datasets/80-20/test_ratings.csv\n",
      "✓ Test set saved (5,204,858 rows)\n",
      "\n",
      "Verifying saved files:\n",
      "  - ../../datasets/output/split_and_train_datasets/80-20/train_ratings.csv\n",
      "    Size: 521.49 MB\n",
      "  - ../../datasets/output/split_and_train_datasets/80-20/test_ratings.csv\n",
      "    Size: 130.37 MB\n",
      "\n",
      "✓ All files saved successfully\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "summary_header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Random Split (80/20) Completed\n",
    "\n",
    "**Method**: Random sampling without temporal considerations\n",
    "\n",
    "**Output Files**:\n",
    "- `train_ratings.csv`: Training set (~80% of data)\n",
    "- `test_ratings.csv`: Test set (~20% of data)\n",
    "\n",
    "**Key Characteristics**:\n",
    "- Random state: 42 (reproducible)\n",
    "- No data leakage (verified no overlap)\n",
    "- Preserved all columns\n",
    "- Rating distributions similar across train/test\n",
    "\n",
    "**Next Steps**:\n",
    "1. Use `train_ratings.csv` for model training (collaborative filtering)\n",
    "2. Use `test_ratings.csv` for evaluation (RMSE, MAE, Precision@K)\n",
    "3. Compare with temporal split results (Method 2)"
   ]
  },
  {
   "cell_type": "code",
   "id": "final_stats",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T04:21:45.314554Z",
     "start_time": "2025-10-25T04:21:45.189297Z"
    }
   },
   "source": [
    "# Final summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM SPLIT (80/20) - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOriginal Dataset: {len(ratings):,} ratings\")\n",
    "print(f\"\\nTraining Set: {len(train):,} ratings ({len(train)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Users: {train['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {train['movieId'].nunique():,}\")\n",
    "print(f\"  - Avg rating: {train['rating'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set: {len(test):,} ratings ({len(test)/len(ratings)*100:.2f}%)\")\n",
    "print(f\"  - Users: {test['userId'].nunique():,}\")\n",
    "print(f\"  - Movies: {test['movieId'].nunique():,}\")\n",
    "print(f\"  - Avg rating: {test['rating'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nOutput Location: {output_dir}\")\n",
    "print(f\"  - train_ratings.csv ({train_size_mb:.2f} MB)\")\n",
    "print(f\"  - test_ratings.csv ({test_size_mb:.2f} MB)\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Random split completed successfully\")\n",
    "print(\"=\"*60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM SPLIT (80/20) - FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Original Dataset: 26,024,289 ratings\n",
      "\n",
      "Training Set: 20,819,431 ratings (80.00%)\n",
      "  - Users: 269,710\n",
      "  - Movies: 43,326\n",
      "  - Avg rating: 3.5281\n",
      "\n",
      "Test Set: 5,204,858 ratings (20.00%)\n",
      "  - Users: 253,107\n",
      "  - Movies: 31,629\n",
      "  - Avg rating: 3.5279\n",
      "\n",
      "Output Location: ../../datasets/output/split_and_train_datasets/80-20/\n",
      "  - train_ratings.csv (521.49 MB)\n",
      "  - test_ratings.csv (130.37 MB)\n",
      "\n",
      "============================================================\n",
      "✓ Random split completed successfully\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cc930ca6c57ba416"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
